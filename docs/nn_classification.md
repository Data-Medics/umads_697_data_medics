# Deep Learning Classification Models

To complete our model evaluation we also chose to test several variations of deep learning models.  Given the high performance on many benchmark assessments that neural networks have achieved in the past several years, and especially their performance on natural language data we wanted to test several neural networks on our data set.  To begin we built a fairly simple Embedding Bag model using PyTorch.  An embedding bag can be thought of as a two step process (although this is not implemented as a two step process in PyTorch).  First, all the sentences in a batch are combined into one long tensor and the tensor is embedded into some n-dimensional space, also known as the embedding dimension, which is chosen by the user.  Next, a reduction (mean, min, max, etc.) is applied across the embedded latent dimension and this is passed to a fully connected layer which then produces the predictions.  This neural architecture is similar to what would happen if you vectorized text via one of the many methods discussed throughout the UMADS program, word2vec, tf-idf, and others, then passed this output into a fully-connected neural network.  It is simple but very fast, and achieved performance similar to that of our standard logistic regression.  

One major weakness of the embedding algorithm is that it does not consider the order of the words or structure of the sentence - all words are embedded simultaneously.  We felt it would be valuable to also evaluate a more sophisticated model that makes some of these considerations.  For this we chose to incorporate a Long-Short Term Memory (LSTM) neural network.  The architecture was similar to above; the network included an embedding layer (although not an embedding bag - the sentence vectors were not reduced after the embedding) followed by a LSTM followed by several fully connected layers.  We hoped that the LSTM and its ability to consider a tweet as an entity, not just a collection of words, would improve our classification accuracy.  Unfortunately this was not the case.  Even after hyperparameter tuning and several iterations the model architecture (ex: number of layers,  size of embedding and hidden dims, bidirectionality, and more) we were not able to surpass the accuracy of the simpler logistic regression and embedding bag models.  After many epochs we also noticed that the model would begin to overfit and perform very well on the training data while not gaining the same accuracy increases on the validation set.  

While it is possible with more finetuning we would have been able to make slight increases in the model accuracy, we felt the model was limited by the data in several ways.  First, there is such a wide variation in the structure of the texts the words are just as important as the structure, which means that using a LSTM will not significantly increase the accuracy of the model  Additionally, we were working with a fairly small data set, only about 50k records, which impacts the ability of model to learn the data.

In the end we decided to go with a simpler logistic regression model because it is easier to build, train, and maintain than the other deep learning models we tested while performing on par with these models. 
