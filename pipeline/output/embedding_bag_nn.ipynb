{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c379f661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:27.425233Z",
     "iopub.status.busy": "2022-07-16T04:54:27.424828Z",
     "iopub.status.idle": "2022-07-16T04:54:30.038838Z",
     "shell.execute_reply": "2022-07-16T04:54:30.037974Z"
    },
    "papermill": {
     "duration": 2.626646,
     "end_time": "2022-07-16T04:54:30.041729",
     "exception": false,
     "start_time": "2022-07-16T04:54:27.415083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "import time\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354ce0bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:30.056578Z",
     "iopub.status.busy": "2022-07-16T04:54:30.056139Z",
     "iopub.status.idle": "2022-07-16T04:54:30.060210Z",
     "shell.execute_reply": "2022-07-16T04:54:30.059450Z"
    },
    "papermill": {
     "duration": 0.014269,
     "end_time": "2022-07-16T04:54:30.062997",
     "exception": false,
     "start_time": "2022-07-16T04:54:30.048728",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "upstream = []\n",
    "nrows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c21136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:30.077551Z",
     "iopub.status.busy": "2022-07-16T04:54:30.077160Z",
     "iopub.status.idle": "2022-07-16T04:54:30.081400Z",
     "shell.execute_reply": "2022-07-16T04:54:30.080614Z"
    },
    "papermill": {
     "duration": 0.014839,
     "end_time": "2022-07-16T04:54:30.084273",
     "exception": false,
     "start_time": "2022-07-16T04:54:30.069434",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nrows = 500\n",
    "product = {\n",
    "    \"nb\": \"/Users/mboussarov/_umsi/Capstone/umads_697_data_medics/pipeline/output/embedding_bag_nn.ipynb\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c804234c",
   "metadata": {
    "papermill": {
     "duration": 0.006585,
     "end_time": "2022-07-16T04:54:30.097901",
     "exception": false,
     "start_time": "2022-07-16T04:54:30.091316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "project settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dac3e14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:30.111510Z",
     "iopub.status.busy": "2022-07-16T04:54:30.111128Z",
     "iopub.status.idle": "2022-07-16T04:54:30.117294Z",
     "shell.execute_reply": "2022-07-16T04:54:30.116504Z"
    },
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": 0.015938,
     "end_time": "2022-07-16T04:54:30.119848",
     "exception": false,
     "start_time": "2022-07-16T04:54:30.103910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "# project imports\n",
    "import locations as loc\n",
    "\n",
    "# run model on gpu if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c8e890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:30.134377Z",
     "iopub.status.busy": "2022-07-16T04:54:30.133551Z",
     "iopub.status.idle": "2022-07-16T04:54:30.991314Z",
     "shell.execute_reply": "2022-07-16T04:54:30.990446Z"
    },
    "papermill": {
     "duration": 0.867658,
     "end_time": "2022-07-16T04:54:30.994008",
     "exception": false,
     "start_time": "2022-07-16T04:54:30.126350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load a spacy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "971d59dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:31.008393Z",
     "iopub.status.busy": "2022-07-16T04:54:31.008028Z",
     "iopub.status.idle": "2022-07-16T04:54:31.020387Z",
     "shell.execute_reply": "2022-07-16T04:54:31.019622Z"
    },
    "papermill": {
     "duration": 0.022404,
     "end_time": "2022-07-16T04:54:31.022912",
     "exception": false,
     "start_time": "2022-07-16T04:54:31.000508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7ff27ab41f40>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7ff27ee3eb20>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7ff27ee30f20>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7ff27f170c00>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7ff27f109a40>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7ff27ee30d60>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are the transformations the spacy nlp object will perform on every doc\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d76d2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:31.038286Z",
     "iopub.status.busy": "2022-07-16T04:54:31.037502Z",
     "iopub.status.idle": "2022-07-16T04:54:31.081221Z",
     "shell.execute_reply": "2022-07-16T04:54:31.080293Z"
    },
    "papermill": {
     "duration": 0.054191,
     "end_time": "2022-07-16T04:54:31.083746",
     "exception": false,
     "start_time": "2022-07-16T04:54:31.029555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(loc.data, \"all_combined\", \"all_train.tsv\")\n",
    "dev_data_path = os.path.join(loc.data, \"all_combined\", \"all_dev.tsv\")\n",
    "test_data_path = os.path.join(loc.data, \"all_combined\", \"all_test.tsv\")\n",
    "\n",
    "if isinstance(nrows, int):\n",
    "    df = pd.read_csv(data_path, sep=\"\\t\", nrows=nrows)\n",
    "    dev_df = pd.read_csv(dev_data_path, sep=\"\\t\", nrows=nrows)\n",
    "    test_df = pd.read_csv(test_data_path, sep=\"\\t\", nrows=nrows)\n",
    "else:\n",
    "    df = pd.read_csv(data_path, sep=\"\\t\")\n",
    "    dev_df = pd.read_csv(dev_data_path, sep=\"\\t\")\n",
    "    test_df = pd.read_csv(test_data_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1c8cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:31.098786Z",
     "iopub.status.busy": "2022-07-16T04:54:31.098180Z",
     "iopub.status.idle": "2022-07-16T04:54:31.115000Z",
     "shell.execute_reply": "2022-07-16T04:54:31.114128Z"
    },
    "papermill": {
     "duration": 0.02683,
     "end_time": "2022-07-16T04:54:31.117421",
     "exception": false,
     "start_time": "2022-07-16T04:54:31.090591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1031218893908406273</td>\n",
       "      <td>Kerala Floods: More than 38,000 people rescued...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1030767523342499842</td>\n",
       "      <td>@BDUTT While PayTm owner Shekhar donated Rs Te...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1030385981973618688</td>\n",
       "      <td>#KeralaFloods Malayala Manorama makes epaper f...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1031078567147319297</td>\n",
       "      <td>#KeralaSOS #KeralaFloods Lets centralise all r...</td>\n",
       "      <td>sympathy_and_support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1033187418889834497</td>\n",
       "      <td>@narendramodi @AmitShah PS @ kerala is doing t...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0  1031218893908406273  Kerala Floods: More than 38,000 people rescued...   \n",
       "1  1030767523342499842  @BDUTT While PayTm owner Shekhar donated Rs Te...   \n",
       "2  1030385981973618688  #KeralaFloods Malayala Manorama makes epaper f...   \n",
       "3  1031078567147319297  #KeralaSOS #KeralaFloods Lets centralise all r...   \n",
       "4  1033187418889834497  @narendramodi @AmitShah PS @ kerala is doing t...   \n",
       "\n",
       "                              class_label  \n",
       "0  rescue_volunteering_or_donation_effort  \n",
       "1  rescue_volunteering_or_donation_effort  \n",
       "2  rescue_volunteering_or_donation_effort  \n",
       "3                    sympathy_and_support  \n",
       "4  rescue_volunteering_or_donation_effort  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e1b59b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:31.132809Z",
     "iopub.status.busy": "2022-07-16T04:54:31.132181Z",
     "iopub.status.idle": "2022-07-16T04:54:31.141342Z",
     "shell.execute_reply": "2022-07-16T04:54:31.140359Z"
    },
    "papermill": {
     "duration": 0.019402,
     "end_time": "2022-07-16T04:54:31.143751",
     "exception": false,
     "start_time": "2022-07-16T04:54:31.124349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1034712711223885825</td>\n",
       "      <td>RT @Forumkeralam1: #Google to contribute 1 mil...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1031576019675705345</td>\n",
       "      <td>#KeralaFloods: How a WhatsApp group started by...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1031253304288849920</td>\n",
       "      <td>#KeralaFloods Coz humanity matters. #KeralaSOS...</td>\n",
       "      <td>other_relevant_information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1032523376638808064</td>\n",
       "      <td>#KeralaFloods: @SrBachchan donates Rs 51 lakhs...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1032287088190808064</td>\n",
       "      <td>#KeralaFloodRelief #KeralaFloods Guntur Divisi...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0  1034712711223885825  RT @Forumkeralam1: #Google to contribute 1 mil...   \n",
       "1  1031576019675705345  #KeralaFloods: How a WhatsApp group started by...   \n",
       "2  1031253304288849920  #KeralaFloods Coz humanity matters. #KeralaSOS...   \n",
       "3  1032523376638808064  #KeralaFloods: @SrBachchan donates Rs 51 lakhs...   \n",
       "4  1032287088190808064  #KeralaFloodRelief #KeralaFloods Guntur Divisi...   \n",
       "\n",
       "                              class_label  \n",
       "0  rescue_volunteering_or_donation_effort  \n",
       "1  rescue_volunteering_or_donation_effort  \n",
       "2              other_relevant_information  \n",
       "3  rescue_volunteering_or_donation_effort  \n",
       "4  rescue_volunteering_or_donation_effort  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bd6e040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:31.160970Z",
     "iopub.status.busy": "2022-07-16T04:54:31.160298Z",
     "iopub.status.idle": "2022-07-16T04:54:31.169158Z",
     "shell.execute_reply": "2022-07-16T04:54:31.168237Z"
    },
    "papermill": {
     "duration": 0.020669,
     "end_time": "2022-07-16T04:54:31.171498",
     "exception": false,
     "start_time": "2022-07-16T04:54:31.150829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1032436206313725953</td>\n",
       "      <td>Please help my uncle and aunt stranded in Kott...</td>\n",
       "      <td>requests_or_urgent_needs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1035526412445220865</td>\n",
       "      <td>Asian Games : Seema Punia to donate 1 lakh rup...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1033158595146219520</td>\n",
       "      <td>Happy Onam to all our sisters&amp;amp;brothers in ...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1031034992535789570</td>\n",
       "      <td>These are the precautions issued by the Direct...</td>\n",
       "      <td>caution_and_advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1032557601660133376</td>\n",
       "      <td>RT @eastcoastrail: .@RailMinIndia Relief mater...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0  1032436206313725953  Please help my uncle and aunt stranded in Kott...   \n",
       "1  1035526412445220865  Asian Games : Seema Punia to donate 1 lakh rup...   \n",
       "2  1033158595146219520  Happy Onam to all our sisters&amp;brothers in ...   \n",
       "3  1031034992535789570  These are the precautions issued by the Direct...   \n",
       "4  1032557601660133376  RT @eastcoastrail: .@RailMinIndia Relief mater...   \n",
       "\n",
       "                              class_label  \n",
       "0                requests_or_urgent_needs  \n",
       "1  rescue_volunteering_or_donation_effort  \n",
       "2  rescue_volunteering_or_donation_effort  \n",
       "3                      caution_and_advice  \n",
       "4  rescue_volunteering_or_donation_effort  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "809e43af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:31.187602Z",
     "iopub.status.busy": "2022-07-16T04:54:31.187223Z",
     "iopub.status.idle": "2022-07-16T04:54:31.194032Z",
     "shell.execute_reply": "2022-07-16T04:54:31.192997Z"
    },
    "papermill": {
     "duration": 0.017444,
     "end_time": "2022-07-16T04:54:31.196421",
     "exception": false,
     "start_time": "2022-07-16T04:54:31.178977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder_dict = {i: idx for idx, i in enumerate(df[\"class_label\"].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84b03dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:31.212126Z",
     "iopub.status.busy": "2022-07-16T04:54:31.211786Z",
     "iopub.status.idle": "2022-07-16T04:54:36.088668Z",
     "shell.execute_reply": "2022-07-16T04:54:36.087754Z"
    },
    "papermill": {
     "duration": 4.887739,
     "end_time": "2022-07-16T04:54:36.091267",
     "exception": false,
     "start_time": "2022-07-16T04:54:31.203528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply the spacy pipeline to the tweets\n",
    "docs = df[\"tweet_text\"].apply(lambda x: nlp(x))\n",
    "labels = df[\"class_label\"].apply(lambda a: label_encoder_dict[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "539c4283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:36.107858Z",
     "iopub.status.busy": "2022-07-16T04:54:36.107257Z",
     "iopub.status.idle": "2022-07-16T04:54:40.857848Z",
     "shell.execute_reply": "2022-07-16T04:54:40.857022Z"
    },
    "papermill": {
     "duration": 4.761639,
     "end_time": "2022-07-16T04:54:40.860494",
     "exception": false,
     "start_time": "2022-07-16T04:54:36.098855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply the spacy pipeline to the tweets\n",
    "dev_docs = dev_df[\"tweet_text\"].apply(lambda x: nlp(x))\n",
    "dev_labels = dev_df[\"class_label\"].apply(lambda a: label_encoder_dict[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bad727a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:40.877165Z",
     "iopub.status.busy": "2022-07-16T04:54:40.876818Z",
     "iopub.status.idle": "2022-07-16T04:54:45.117558Z",
     "shell.execute_reply": "2022-07-16T04:54:45.116691Z"
    },
    "papermill": {
     "duration": 4.251783,
     "end_time": "2022-07-16T04:54:45.120211",
     "exception": false,
     "start_time": "2022-07-16T04:54:40.868428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply the spacy pipeline to the tweets\n",
    "test_docs = df[\"tweet_text\"].apply(lambda x: nlp(x))\n",
    "test_labels = df[\"class_label\"].apply(lambda a: label_encoder_dict[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b09d9de8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.137225Z",
     "iopub.status.busy": "2022-07-16T04:54:45.136620Z",
     "iopub.status.idle": "2022-07-16T04:54:45.151216Z",
     "shell.execute_reply": "2022-07-16T04:54:45.150373Z"
    },
    "papermill": {
     "duration": 0.026121,
     "end_time": "2022-07-16T04:54:45.154120",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.127999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a corpus of lemmatized docs\n",
    "lemma_docs = []\n",
    "for label, doc in zip(labels, docs):\n",
    "    # if we want to remove stopwords\n",
    "    #     lemma_docs.append((label, ' '.join([token.lemma_ for token in doc if\n",
    "    #                                         token.lemma_ not in stopwords])))\n",
    "    # if we want to keep stopwords in the corpus\n",
    "    lemma_docs.append((label, ' '.join([token.lemma_ for token in doc])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "828c9fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.171584Z",
     "iopub.status.busy": "2022-07-16T04:54:45.171198Z",
     "iopub.status.idle": "2022-07-16T04:54:45.185643Z",
     "shell.execute_reply": "2022-07-16T04:54:45.184812Z"
    },
    "papermill": {
     "duration": 0.025812,
     "end_time": "2022-07-16T04:54:45.188125",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.162313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a corpus of lemmatized docs\n",
    "dev_lemma_docs = []\n",
    "for label, doc in zip(dev_labels, dev_docs):\n",
    "    # if we want to remove stopwords\n",
    "    #     lemma_docs.append((label, ' '.join([token.lemma_ for token in doc if\n",
    "    #                                         token.lemma_ not in stopwords])))\n",
    "    # if we want to keep stopwords in the corpus\n",
    "    dev_lemma_docs.append((label, ' '.join([token.lemma_ for token in doc])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9140fb37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.205510Z",
     "iopub.status.busy": "2022-07-16T04:54:45.204914Z",
     "iopub.status.idle": "2022-07-16T04:54:45.218423Z",
     "shell.execute_reply": "2022-07-16T04:54:45.217661Z"
    },
    "papermill": {
     "duration": 0.024628,
     "end_time": "2022-07-16T04:54:45.220977",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.196349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a corpus of lemmatized docs\n",
    "test_lemma_docs = []\n",
    "for label, doc in zip(test_labels, test_docs):\n",
    "    # if we want to remove stopwords\n",
    "    #     lemma_docs.append((label, ' '.join([token.lemma_ for token in doc if\n",
    "    #                                         token.lemma_ not in stopwords])))\n",
    "    # if we want to keep stopwords in the corpus\n",
    "    test_lemma_docs.append((label, ' '.join([token.lemma_ for token in doc])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d9709cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.237948Z",
     "iopub.status.busy": "2022-07-16T04:54:45.237316Z",
     "iopub.status.idle": "2022-07-16T04:54:45.241303Z",
     "shell.execute_reply": "2022-07-16T04:54:45.240265Z"
    },
    "papermill": {
     "duration": 0.01498,
     "end_time": "2022-07-16T04:54:45.243662",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.228682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see the lemmatized docs\n",
    "# lemma_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b108e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.260906Z",
     "iopub.status.busy": "2022-07-16T04:54:45.260275Z",
     "iopub.status.idle": "2022-07-16T04:54:45.265353Z",
     "shell.execute_reply": "2022-07-16T04:54:45.264295Z"
    },
    "papermill": {
     "duration": 0.017401,
     "end_time": "2022-07-16T04:54:45.268546",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.251145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemma_sents_file_location = os.path.join(\".\", \"output\", \"train_lemma_sents.txt\")\n",
    "dev_lemma_sents_file_location = os.path.join(\".\", \"output\", \"dev_lemma_sents.txt\")\n",
    "test_lemma_sents_file_location = os.path.join(\".\", \"output\", \"test_lemma_sents.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2487348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.286322Z",
     "iopub.status.busy": "2022-07-16T04:54:45.285668Z",
     "iopub.status.idle": "2022-07-16T04:54:45.291661Z",
     "shell.execute_reply": "2022-07-16T04:54:45.290840Z"
    },
    "papermill": {
     "duration": 0.017367,
     "end_time": "2022-07-16T04:54:45.294232",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.276865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint - write lemmatized sentences to txt\n",
    "\n",
    "with open(lemma_sents_file_location, \"w\") as f:\n",
    "    for s in lemma_docs:\n",
    "        f.write(str(s[0]))\n",
    "        f.write(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13292ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.311435Z",
     "iopub.status.busy": "2022-07-16T04:54:45.310845Z",
     "iopub.status.idle": "2022-07-16T04:54:45.316636Z",
     "shell.execute_reply": "2022-07-16T04:54:45.315786Z"
    },
    "papermill": {
     "duration": 0.017223,
     "end_time": "2022-07-16T04:54:45.319121",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.301898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(dev_lemma_sents_file_location, \"w\") as f:\n",
    "    for s in dev_lemma_docs:\n",
    "        f.write(str(s[0]))\n",
    "        f.write(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00015038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.335942Z",
     "iopub.status.busy": "2022-07-16T04:54:45.335348Z",
     "iopub.status.idle": "2022-07-16T04:54:45.341093Z",
     "shell.execute_reply": "2022-07-16T04:54:45.340359Z"
    },
    "papermill": {
     "duration": 0.016934,
     "end_time": "2022-07-16T04:54:45.343530",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.326596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(test_lemma_sents_file_location, \"w\") as f:\n",
    "    for s in test_lemma_docs:\n",
    "        f.write(str(s[0]))\n",
    "        f.write(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c61f1cda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.361363Z",
     "iopub.status.busy": "2022-07-16T04:54:45.360468Z",
     "iopub.status.idle": "2022-07-16T04:54:45.366293Z",
     "shell.execute_reply": "2022-07-16T04:54:45.365459Z"
    },
    "papermill": {
     "duration": 0.017049,
     "end_time": "2022-07-16T04:54:45.368803",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.351754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the lemmatized sentence\n",
    "with open(lemma_sents_file_location, \"r\") as f:\n",
    "    doc = f.readlines()\n",
    "\n",
    "lemma_docs = []\n",
    "for text in doc:\n",
    "    lemma_docs.append((text[0], text[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16191225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.387567Z",
     "iopub.status.busy": "2022-07-16T04:54:45.386892Z",
     "iopub.status.idle": "2022-07-16T04:54:45.392443Z",
     "shell.execute_reply": "2022-07-16T04:54:45.391677Z"
    },
    "papermill": {
     "duration": 0.01831,
     "end_time": "2022-07-16T04:54:45.394866",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.376556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(dev_lemma_sents_file_location, \"r\") as f:\n",
    "    doc = f.readlines()\n",
    "\n",
    "dev_lemma_docs = []\n",
    "for text in doc:\n",
    "    dev_lemma_docs.append((text[0], text[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97199c47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.412230Z",
     "iopub.status.busy": "2022-07-16T04:54:45.411513Z",
     "iopub.status.idle": "2022-07-16T04:54:45.417374Z",
     "shell.execute_reply": "2022-07-16T04:54:45.416591Z"
    },
    "papermill": {
     "duration": 0.017007,
     "end_time": "2022-07-16T04:54:45.419740",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.402733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(test_lemma_sents_file_location, \"r\") as f:\n",
    "    doc = f.readlines()\n",
    "\n",
    "test_lemma_docs = []\n",
    "for text in doc:\n",
    "    test_lemma_docs.append((text[0], text[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4619214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.437066Z",
     "iopub.status.busy": "2022-07-16T04:54:45.436325Z",
     "iopub.status.idle": "2022-07-16T04:54:45.440690Z",
     "shell.execute_reply": "2022-07-16T04:54:45.439696Z"
    },
    "papermill": {
     "duration": 0.015475,
     "end_time": "2022-07-16T04:54:45.443131",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.427656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #### Prepare and build the RNN\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa48ecdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.460575Z",
     "iopub.status.busy": "2022-07-16T04:54:45.459925Z",
     "iopub.status.idle": "2022-07-16T04:54:45.467280Z",
     "shell.execute_reply": "2022-07-16T04:54:45.466508Z"
    },
    "papermill": {
     "duration": 0.018771,
     "end_time": "2022-07-16T04:54:45.469791",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.451020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pytorch helper functions\n",
    "\n",
    "def yield_tokens(doc_strings):\n",
    "    # discard the label because it does not need to be tokenized\n",
    "    for _, text in doc_strings:\n",
    "        # yield the tokenized text\n",
    "        yield tokenizer(text)\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_transform(_label))\n",
    "        processed_text = torch.tensor(text_transform(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa5c79f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.487887Z",
     "iopub.status.busy": "2022-07-16T04:54:45.487260Z",
     "iopub.status.idle": "2022-07-16T04:54:45.491474Z",
     "shell.execute_reply": "2022-07-16T04:54:45.490617Z"
    },
    "papermill": {
     "duration": 0.016033,
     "end_time": "2022-07-16T04:54:45.493919",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.477886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the torchtext tokenizer\n",
    "# a little redundent because we have spacy, but this allows for the entire pipeline to run\n",
    "# in torch if we want\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a912b3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.513846Z",
     "iopub.status.busy": "2022-07-16T04:54:45.512984Z",
     "iopub.status.idle": "2022-07-16T04:54:45.607990Z",
     "shell.execute_reply": "2022-07-16T04:54:45.607146Z"
    },
    "papermill": {
     "duration": 0.107312,
     "end_time": "2022-07-16T04:54:45.610422",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.503110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the torch encodings\n",
    "# add a special character for out of bag words\n",
    "vocab = build_vocab_from_iterator(yield_tokens(lemma_docs), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "437fc2c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.628067Z",
     "iopub.status.busy": "2022-07-16T04:54:45.627470Z",
     "iopub.status.idle": "2022-07-16T04:54:45.631932Z",
     "shell.execute_reply": "2022-07-16T04:54:45.631156Z"
    },
    "papermill": {
     "duration": 0.015876,
     "end_time": "2022-07-16T04:54:45.634398",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.618522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_transform = lambda x: vocab(tokenizer(x))\n",
    "label_transform = lambda x: int(x)\n",
    "\n",
    "\n",
    "# create the data loader\n",
    "# dataloader = DataLoader(lemma_docs, batch_size=8, shuffle=False, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a398c1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.652863Z",
     "iopub.status.busy": "2022-07-16T04:54:45.652053Z",
     "iopub.status.idle": "2022-07-16T04:54:45.659309Z",
     "shell.execute_reply": "2022-07-16T04:54:45.658465Z"
    },
    "papermill": {
     "duration": 0.019386,
     "end_time": "2022-07-16T04:54:45.662032",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.642646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "class TweetClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TweetClassificationModel, self).__init__()\n",
    "        # use an EmbeddingBag as the \"text\" portion of the model\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        # traditional Linear layer as the final output\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        # initialize the weights - this will help convergence\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        # run a forward pass through the NN\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27d855c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.681959Z",
     "iopub.status.busy": "2022-07-16T04:54:45.681291Z",
     "iopub.status.idle": "2022-07-16T04:54:45.698086Z",
     "shell.execute_reply": "2022-07-16T04:54:45.697271Z"
    },
    "papermill": {
     "duration": 0.028568,
     "end_time": "2022-07-16T04:54:45.700544",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.671976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model run variables\n",
    "num_class = len(set([a[0] for a in lemma_docs]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "# instantiate model\n",
    "model = TweetClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2034ae89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.718373Z",
     "iopub.status.busy": "2022-07-16T04:54:45.717792Z",
     "iopub.status.idle": "2022-07-16T04:54:45.727320Z",
     "shell.execute_reply": "2022-07-16T04:54:45.726490Z"
    },
    "papermill": {
     "duration": 0.021012,
     "end_time": "2022-07-16T04:54:45.729715",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.708703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the training loop\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        #         zero out the gradient for a new run\n",
    "        optimizer.zero_grad()\n",
    "        # create a prediction\n",
    "        predicted_label = model(text, offsets)\n",
    "        # calculate loss and run backprop\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % 100 == 0 and idx > 0:\n",
    "            accuracy = total_acc / total_count\n",
    "            print(f\"Epoch: {epoch} Batch: {idx / 100} Accuracy: {accuracy:.2f}\\n\")\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43077f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-16T04:54:45.748351Z",
     "iopub.status.busy": "2022-07-16T04:54:45.747681Z",
     "iopub.status.idle": "2022-07-16T04:54:46.215405Z",
     "shell.execute_reply": "2022-07-16T04:54:46.214488Z"
    },
    "papermill": {
     "duration": 0.479896,
     "end_time": "2022-07-16T04:54:46.217991",
     "exception": false,
     "start_time": "2022-07-16T04:54:45.738095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "\n",
      "VALIDATION SET: Epoch: 1 Accuracy: 1.00\n",
      "\n",
      "#########################\n",
      "#########################\n",
      "\n",
      "VALIDATION SET: Epoch: 2 Accuracy: 1.00\n",
      "\n",
      "#########################\n",
      "#########################\n",
      "\n",
      "VALIDATION SET: Epoch: 3 Accuracy: 1.00\n",
      "\n",
      "#########################\n",
      "#########################\n",
      "\n",
      "VALIDATION SET: Epoch: 4 Accuracy: 1.00\n",
      "\n",
      "#########################\n",
      "#########################\n",
      "\n",
      "VALIDATION SET: Epoch: 5 Accuracy: 1.00\n",
      "\n",
      "#########################\n",
      "#########################\n",
      "\n",
      "VALIDATION SET: Epoch: 6 Accuracy: 1.00\n",
      "\n",
      "#########################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "\n",
      "VALIDATION SET: Epoch: 7 Accuracy: 1.00\n",
      "\n",
      "#########################\n",
      "#########################\n",
      "\n",
      "VALIDATION SET: Epoch: 8 Accuracy: 1.00\n",
      "\n",
      "#########################\n",
      "#########################\n",
      "\n",
      "VALIDATION SET: Epoch: 9 Accuracy: 1.00\n",
      "\n",
      "#########################\n",
      "#########################\n",
      "\n",
      "VALIDATION SET: Epoch: 10 Accuracy: 1.00\n",
      "\n",
      "#########################\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 10  # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64  # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "\n",
    "train_dataloader = DataLoader(lemma_docs, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(dev_lemma_docs, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_lemma_docs, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('#' * 25)\n",
    "\n",
    "    print(f\"\\nVALIDATION SET: Epoch: {epoch} Accuracy: {accu_val:.2f}\\n\")\n",
    "\n",
    "    print('#' * 25)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "duration": 20.792212,
   "end_time": "2022-07-16T04:54:46.852549",
   "exception": null,
   "input_path": "/var/folders/lw/k7hqg3bn7s326rs6jxn046b40000gp/T/tmptq2sful6.ipynb",
   "output_path": "/Users/mboussarov/_umsi/Capstone/umads_697_data_medics/pipeline/output/embedding_bag_nn.ipynb",
   "parameters": {
    "nrows": 500,
    "product": {
     "nb": "/Users/mboussarov/_umsi/Capstone/umads_697_data_medics/pipeline/output/embedding_bag_nn.ipynb"
    }
   },
   "start_time": "2022-07-16T04:54:26.060337"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}